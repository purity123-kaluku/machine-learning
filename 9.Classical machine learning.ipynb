{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d9629b-1bcb-40f0-9c32-39d984f31284",
   "metadata": {},
   "source": [
    "## Classical machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b791d4a-e9fe-4257-9af5-8f8a44857c16",
   "metadata": {},
   "source": [
    "Classical machine learning refers to the traditional algorithms and techniques developed primarily from the mid-20th century through the early 2000s. These methods often rely on well-defined mathematical principles and statistical theory. Unlike more recent developments in deep learning, which utilize neural networks with multiple layers, classical machine learning algorithms typically focus on simpler models that can be trained and evaluated with less computational resources.\n",
    "\n",
    "### Characteristics of Classical Machine Learning:\n",
    "\n",
    "1. **Interpretability**: Many classical algorithms produce models that are easier to interpret and understand, which is crucial for applications where explainability is important.\n",
    "\n",
    "2. **Efficiency**: Classical algorithms often require less computational power and are faster to train compared to deep learning models.\n",
    "\n",
    "3. **Smaller Datasets**: These methods can work well with relatively smaller datasets, whereas deep learning generally requires large amounts of data to perform well.\n",
    "\n",
    "4. **Feature Engineering**: Classical machine learning heavily relies on manually engineered features, which requires domain expertise to identify and create relevant features.\n",
    "\n",
    "### Common Classical Machine Learning Algorithms:\n",
    "\n",
    "1. **Linear Regression**:\n",
    "   - **Type**: Regression\n",
    "   - **Description**: Models the relationship between a dependent variable and one or more independent variables using a linear equation.\n",
    "   - **Use Cases**: Predicting house prices, stock prices.\n",
    "\n",
    "2. **Logistic Regression**:\n",
    "   - **Type**: Classification\n",
    "   - **Description**: Models the probability of a binary outcome using a logistic function.\n",
    "   - **Use Cases**: Spam detection, disease diagnosis.\n",
    "\n",
    "3. **Decision Trees**:\n",
    "   - **Type**: Classification and Regression\n",
    "   - **Description**: Splits the data into subsets based on feature values, creating a tree-like model of decisions.\n",
    "   - **Use Cases**: Customer segmentation, loan approval.\n",
    "\n",
    "4. **Random Forests**:\n",
    "   - **Type**: Classification and Regression\n",
    "   - **Description**: An ensemble method that builds multiple decision trees and merges their results.\n",
    "   - **Use Cases**: Fraud detection, feature importance analysis.\n",
    "\n",
    "5. **Support Vector Machines (SVM)**:\n",
    "   - **Type**: Classification and Regression\n",
    "   - **Description**: Finds the hyperplane that best separates data into classes.\n",
    "   - **Use Cases**: Text classification, image recognition.\n",
    "\n",
    "6. **K-Nearest Neighbors (KNN)**:\n",
    "   - **Type**: Classification and Regression\n",
    "   - **Description**: Classifies a data point based on the majority class of its K nearest neighbors.\n",
    "   - **Use Cases**: Recommender systems, pattern recognition.\n",
    "\n",
    "7. **Naive Bayes**:\n",
    "   - **Type**: Classification\n",
    "   - **Description**: Based on Bayes' theorem, assumes independence between features.\n",
    "   - **Use Cases**: Email filtering, sentiment analysis.\n",
    "\n",
    "8. **K-Means Clustering**:\n",
    "   - **Type**: Clustering\n",
    "   - **Description**: Partitions data into K clusters based on feature similarity.\n",
    "   - **Use Cases**: Market segmentation, document clustering.\n",
    "\n",
    "9. **Principal Component Analysis (PCA)**:\n",
    "   - **Type**: Dimensionality Reduction\n",
    "   - **Description**: Reduces the dimensionality of data while preserving variance by transforming to a new set of orthogonal features.\n",
    "   - **Use Cases**: Image compression, exploratory data analysis.\n",
    "\n",
    "### Advantages of Classical Machine Learning:\n",
    "\n",
    "- **Simplicity**: Easier to understand and implement.\n",
    "- **Less Data Intensive**: Often performs well with smaller datasets.\n",
    "- **Speed**: Faster training times and less computationally expensive.\n",
    "- **Interpretability**: Models are often more transparent and easier to interpret.\n",
    "\n",
    "### Limitations of Classical Machine Learning:\n",
    "\n",
    "- **Manual Feature Engineering**: Requires significant domain expertise to create and select relevant features.\n",
    "- **Performance on Complex Data**: May not perform as well on highly complex tasks such as image or speech recognition, which benefit from the deep learning approach.\n",
    "- **Scalability**: Some algorithms may struggle with very large datasets or high-dimensional data.\n",
    "\n",
    "Classical machine learning remains a fundamental and widely used approach in data science, especially for tasks where interpretability, efficiency, and the availability of smaller datasets are key considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff5f5c-ba4b-45fe-b872-f2f1e13910f5",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc81b8-3bbb-4e07-ac18-9068a3ad4fca",
   "metadata": {},
   "source": [
    " decision tree is a supervised learning algorithm. It operates like a flowchart. You can think of a flowchart as an upside-down decision tree. The flowchart has a root node (where the flowchart begins), branches that connect to internal nodes, and more branches that connect to leaf nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43293e-74b1-4efe-b283-a886b303e61c",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8343e76-88f2-46ef-a209-f5441e1349ed",
   "metadata": {},
   "source": [
    "Linear regression is another type of algorithm. It relates to data that might be graphed as a straight line. For example, a business might believe that more advertising spending leads to better sales. This could be graphed as a series of dots that form a rising straight line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d9f2f-3971-47f4-822b-99dd9740aab5",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89383e-abaa-45bd-b533-cce5ad2609d5",
   "metadata": {},
   "source": [
    "In some situations, a relationship does not fall in a straight line. Sometimes a system uses values that require a specific, limited kind of outcome, such as something between 0 and 1 (or NO and YES). In this situation, a graph can form whatâ€™s called a sigmoid function, or an S-shaped curve, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18dbfd-723c-40b2-804a-f23989d80457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
