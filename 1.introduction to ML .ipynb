{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014feeb7-2398-4238-892a-c1be5c044981",
   "metadata": {},
   "source": [
    "Machine learning is a branch of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to perform tasks without explicit instructions. Instead, these algorithms learn from and make predictions or decisions based on data. Here’s a more detailed breakdown:\n",
    "\n",
    "1. **Definition**:\n",
    "   - **Machine Learning (ML)**: A field of AI focused on creating systems that learn from data, identify patterns, and make decisions with minimal human intervention.\n",
    "\n",
    "2. **Types of Machine Learning**:\n",
    "   - **Supervised Learning**: The algorithm learns from labeled data. The training dataset includes input-output pairs, and the model makes predictions based on this data.\n",
    "     - Examples: Regression, Classification.\n",
    "   - **Unsupervised Learning**: The algorithm learns from unlabeled data. It identifies patterns and relationships in the data without predefined labels.\n",
    "     - Examples: Clustering, Association.\n",
    "   - **Semi-Supervised Learning**: Combines labeled and unlabeled data to improve learning accuracy. This approach is useful when obtaining a fully labeled dataset is challenging.\n",
    "   - **Reinforcement Learning**: The algorithm learns by interacting with an environment, receiving feedback through rewards or penalties, and aims to maximize cumulative rewards.\n",
    "     - Examples: Game playing, Robotics.\n",
    "\n",
    "3. **Key Concepts**:\n",
    "   - **Algorithms**: Procedures or formulas for solving problems. Examples include decision trees, neural networks, and support vector machines.\n",
    "   - **Training**: The process of teaching a model by feeding it data and allowing it to adjust its parameters.\n",
    "   - **Model**: The output of the training process, which can be used to make predictions or decisions.\n",
    "   - **Features**: Individual measurable properties or characteristics of the data.\n",
    "   - **Labels**: The output or target value in supervised learning.\n",
    "\n",
    "4. **Applications**:\n",
    "   - **Image and Speech Recognition**: Identifying objects in images or transcribing spoken words.\n",
    "   - **Natural Language Processing (NLP)**: Understanding and generating human language, such as in chatbots or translation services.\n",
    "   - **Recommendation Systems**: Suggesting products or content based on user behavior.\n",
    "   - **Predictive Analytics**: Forecasting future trends based on historical data, used in finance, healthcare, and more.\n",
    "   - **Autonomous Systems**: Enabling vehicles or robots to navigate and make decisions without human intervention.\n",
    "\n",
    "5. **Challenges**:\n",
    "   - **Data Quality and Quantity**: High-quality, relevant data is essential for training effective models.\n",
    "   - **Overfitting and Underfitting**: Creating models that generalize well to new, unseen data, rather than just memorizing the training data.\n",
    "   - **Interpretability**: Understanding and explaining how models make decisions, which is particularly important in critical applications like healthcare and finance.\n",
    "   - **Ethics and Bias**: Ensuring models do not perpetuate or amplify biases present in the training data.\n",
    "\n",
    "Machine learning is a rapidly evolving field with a wide range of techniques and applications, and it plays a crucial role in the development of intelligent systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be48c8d-d8b8-4ffb-978b-abf7e8a7cd9b",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "In the mind of a computer, a data set is any collection of data. It can be anything from an array to a complete database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab1f33-b703-458b-9bef-41fa58edf80c",
   "metadata": {},
   "source": [
    "## Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a94bdf-0ea4-475b-9bbc-68c1e4e79dc5",
   "metadata": {},
   "source": [
    "To analyze data, it is important to know what type of data we are dealing with.\n",
    "\n",
    "We can split the data types into three main categories:\n",
    "\n",
    "- Numerical\n",
    "- Categorical\n",
    "- Ordinal\n",
    "Numerical data are numbers, and can be split into two numerical categories:\n",
    "\n",
    "`Discrete Data`\n",
    "\n",
    "- counted data that are limited to integers. Example: The number of cars passing by.\n",
    "\n",
    "`Continuous Data`\n",
    "\n",
    "-  measured data that can be any number. Example: The price of an item, or the size of an item\n",
    "\n",
    "`Categorical data`\n",
    "\n",
    "\n",
    "-  are values that cannot be measured up against each other. Example: a color value, or any yes/no values.\n",
    "\n",
    "`Ordinal data`\n",
    "\n",
    "- are like categorical data, but can be measured up against each other. Example: school grades where A is better than B and so on.\n",
    "\n",
    "By knowing the data type of your data source, you will be able to know what technique to use when analyzing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4c7d85-2b7d-4a3f-b5c0-8812e6bd8dac",
   "metadata": {},
   "source": [
    "## Machine Learning - Mean Median Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da965f9c-e9e2-4540-aafc-bc7417096ad4",
   "metadata": {},
   "source": [
    "In machine learning and statistics, mean, median, and mode are basic measures of central tendency that are used to summarize and understand datasets. Here’s a detailed explanation of each:\n",
    "\n",
    "### Mean\n",
    "The mean (or average) is the sum of all values in a dataset divided by the number of values.\n",
    "\n",
    "- **Formula**:\n",
    "  \\[\n",
    "  \\text{Mean} = \\frac{\\sum_{i=1}^{n} x_i}{n}\n",
    "  \\]\n",
    "  where \\( x_i \\) represents each value in the dataset, and \\( n \\) is the total number of values.\n",
    "\n",
    "- **Use Case**: The mean is useful when you want a quick sense of the average value in your dataset. It is sensitive to outliers, meaning that extreme values can significantly affect the mean.\n",
    "\n",
    "### Median\n",
    "The median is the middle value of a dataset when it is ordered from least to greatest. If the dataset has an even number of values, the median is the average of the two middle values.\n",
    "\n",
    "- **Steps to Find Median**:\n",
    "  1. Sort the dataset in ascending order.\n",
    "  2. If the number of observations (n) is odd, the median is the middle value.\n",
    "  3. If \\( n \\) is even, the median is the average of the two middle values.\n",
    "\n",
    "- **Use Case**: The median is useful for understanding the central tendency of a dataset without being affected by outliers or skewed data.\n",
    "\n",
    "### Mode\n",
    "The mode is the value that appears most frequently in a dataset. A dataset can have one mode (unimodal), more than one mode (bimodal or multimodal), or no mode at all if no value repeats.\n",
    "\n",
    "- **Use Case**: The mode is useful for categorical data where you want to know which is the most common category. It is less informative for continuous data unless you are interested in the most frequent values.\n",
    "\n",
    "### Examples\n",
    "Let's consider a dataset: [3, 7, 8, 5, 12, 14, 21, 13, 18, 14]\n",
    "\n",
    "- **Mean**:\n",
    "  \\[\n",
    "  \\text{Mean} = \\frac{3 + 7 + 8 + 5 + 12 + 14 + 21 + 13 + 18 + 14}{10} = \\frac{115}{10} = 11.5\n",
    "  \\]\n",
    "\n",
    "- **Median**:\n",
    "  - Sorted dataset: [3, 5, 7, 8, 12, 13, 14, 14, 18, 21]\n",
    "  - Number of values (n) = 10 (even)\n",
    "  - Median = \\(\\frac{12 + 13}{2} = 12.5\\)\n",
    "\n",
    "- **Mode**:\n",
    "  - The value 14 appears most frequently (twice).\n",
    "  - Mode = 14\n",
    "\n",
    "### Application in Machine Learning\n",
    "- **Data Preprocessing**: Mean, median, and mode are often used in preprocessing steps, such as imputing missing values. For example, you might fill missing values with the median if the data is skewed.\n",
    "- **Feature Engineering**: These statistics can help in creating new features that might improve model performance.\n",
    "- **Model Evaluation**: Understanding the central tendency of your predictions can help in evaluating the performance of regression models.\n",
    "\n",
    "By using these measures of central tendency, you can gain insights into your dataset, detect anomalies, and make informed decisions during the data analysis and preprocessing stages in machine learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6cf29-adab-4f3d-8b23-98e8d790cb16",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181590bd-69b5-4806-a0d5-60f745eaf295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.76923076923077\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n",
    "\n",
    "x = numpy.mean(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b97384-8d04-40cf-b414-6dc0eb1e90f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "data = np.array([4, 8, 15, 16, 23, 42])\n",
    "\n",
    "# Calculate the mean\n",
    "mean = np.mean(data)\n",
    "print(mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65368589-6517-4a06-a93a-dc712c3bacad",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36a75840-8cba-413e-a4d1-f6ac33293e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n",
    "\n",
    "x = numpy.median(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11f0529-2fbb-423c-9da5-d09c805b4655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median (odd): 3\n",
      "Median (even): 4.0\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "data_odd = [3, 1, 4, 1, 5]\n",
    "data_even = [7, 3, 1, 5]\n",
    "\n",
    "# Calculate the median for odd number of values\n",
    "data_odd_sorted = sorted(data_odd)\n",
    "n_odd = len(data_odd_sorted)\n",
    "median_odd = data_odd_sorted[n_odd // 2]\n",
    "\n",
    "# Calculate the median for even number of values\n",
    "data_even_sorted = sorted(data_even)\n",
    "n_even = len(data_even_sorted)\n",
    "median_even = (data_even_sorted[n_even // 2 - 1] + data_even_sorted[n_even // 2]) / 2\n",
    "\n",
    "print(\"Median (odd):\", median_odd)\n",
    "print(\"Median (even):\", median_even)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d513c1-10a2-4b68-bb41-aa4dc991f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [99,86,87,88,86,103,87,94,78,77,85,86]\n",
    "\n",
    "x = numpy.median(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc524cc6-4031-4f3e-b7f4-aceda73c1137",
   "metadata": {},
   "source": [
    "### Mode\n",
    "-The Mode value is the value that appears the most number of times\n",
    "-The `SciPy module` has a method for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d5055a-24ad-426b-9470-42c496a20a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeResult(mode=86, count=3)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "speed = [99,86,87,88,111,86,103,87,94,78,77,85,86]\n",
    "\n",
    "x = stats.mode(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a09d0a30-c0f5-4ebe-b907-30ecf2948c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModeResult(mode=5, count=3)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "data = [1, 2, 3, 4, 4, 5, 5, 5, 6]\n",
    "\n",
    "mode_result = stats.mode(data)\n",
    "print(mode_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a9f45-446f-4f0a-82e4-5ebd32d82f7a",
   "metadata": {},
   "source": [
    "## Machine Learning - Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f87ff4-aab2-476c-a162-ea4acdac524c",
   "metadata": {},
   "source": [
    "In machine learning, standard deviation is a measure of the dispersion or spread of a dataset. It indicates how much individual data points differ from the mean of the dataset. A low standard deviation suggests that the data points tend to be close to the mean, while a high standard deviation indicates that the data points are spread out over a wider range of values.\n",
    "\n",
    "### Calculating Standard Deviation\n",
    "The standard deviation (σ) of a dataset is calculated using the following formula:\n",
    "\n",
    "\\[\n",
    "\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(x_i\\) represents each value in the dataset.\n",
    "- \\(\\mu\\) is the mean of the dataset.\n",
    "- \\(n\\) is the total number of values.\n",
    "\n",
    "### Steps to Calculate Standard Deviation\n",
    "1. **Calculate the Mean**: Find the mean (average) of the dataset.\n",
    "2. **Calculate the Deviation**: Subtract the mean from each value to find the deviation from the mean.\n",
    "3. **Square the Deviation**: Square each deviation to eliminate negative values.\n",
    "4. **Calculate the Mean of Squared Deviations**: Find the mean of the squared deviations.\n",
    "5. **Take the Square Root**: Finally, take the square root of the mean of squared deviations to obtain the standard deviation.\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Consider the dataset: [2, 4, 4, 4, 5, 5, 7, 9].\n",
    "\n",
    "1. **Calculate the Mean**:\n",
    "   \\[\n",
    "   \\text{Mean} = \\frac{2 + 4 + 4 + 4 + 5 + 5 + 7 + 9}{8} = \\frac{40}{8} = 5\n",
    "   \\]\n",
    "\n",
    "2. **Calculate the Deviation**:\n",
    "   Deviations: [-3, -1, -1, -1, 0, 0, 2, 4]\n",
    "\n",
    "3. **Square the Deviation**:\n",
    "   Squared deviations: [9, 1, 1, 1, 0, 0, 4, 16]\n",
    "\n",
    "4. **Calculate the Mean of Squared Deviations**:\n",
    "   \\[\n",
    "   \\text{Mean of Squared Deviations} = \\frac{9 + 1 + 1 + 1 + 0 + 0 + 4 + 16}{8} = \\frac{32}{8} = 4\n",
    "   \\]\n",
    "\n",
    "5. **Take the Square Root**:\n",
    "   \\[\n",
    "   \\text{Standard Deviation} = \\sqrt{4} = 2\n",
    "   \\]\n",
    "\n",
    "### Applications in Machine Learning\n",
    "\n",
    "- **Data Understanding**: Standard deviation provides insights into the variability of data points in a dataset.\n",
    "- **Feature Selection**: Standard deviation can be used as a feature selection criterion. Features with low variability may be less informative for predictive modeling.\n",
    "- **Model Evaluation**: Standard deviation is used in various evaluation metrics, such as standard deviation of residuals in regression analysis or standard deviation of accuracy scores in cross-validation.\n",
    "\n",
    "### Example in Python\n",
    "\n",
    "Here's how you can calculate the standard deviation using Python with a dataset stored in a list:\n",
    "\n",
    "```python\n",
    "import statistics\n",
    "\n",
    "data = [2, 4, 4, 4, 5, 5, 7, 9]\n",
    "\n",
    "std_dev = statistics.stdev(data)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "```\n",
    "\n",
    "Alternatively, you can use NumPy for more efficient computation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n",
    "\n",
    "std_dev = np.std(data)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "```\n",
    "\n",
    "### Importance in Machine Learning\n",
    "\n",
    "- **Data Quality**: Understanding the variability of features helps in assessing data quality and identifying potential issues.\n",
    "- **Feature Engineering**: Standard deviation can be used to create new features or transform existing features to improve model performance.\n",
    "- **Model Training**: Standard deviation is used in various algorithms and techniques, such as outlier detection, normalization, and scaling.\n",
    "- **Model Evaluation**: Standard deviation-based metrics provide insights into the variability of model predictions and can help in comparing different models' performance.\n",
    "\n",
    "By effectively understanding and utilizing standard deviation, machine learning practitioners can enhance their data analysis, preprocessing, and modeling processes, leading to more accurate and robust machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e53dc40-4537-4bba-ba77-0df973f5b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n",
    "\n",
    "std_dev = np.std(data)\n",
    "print( std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51afb1f7-8d48-4d60-8234-f46063f14cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9035079029052513\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [86,87,88,86,87,85,86]\n",
    "\n",
    "x = numpy.std(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8acda46-06f8-4029-8524-b9e65103a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.84501153334721\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [32,111,138,28,59,77,97]\n",
    "\n",
    "x = numpy.std(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2132b-3980-45e3-85cd-3f9e246c5d16",
   "metadata": {},
   "source": [
    "- A low standard deviation means that most of the numbers are close to the mean (average) value.\n",
    "\n",
    "- A high standard deviation means that the values are spread out over a wider range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e90a07-91dd-40ef-a027-f733e7a0cfb2",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c60c80-ac16-414d-87d1-8080182f9d60",
   "metadata": {},
   "source": [
    "- Variance is another number that indicates how spread out the values are.\n",
    "\n",
    "- In fact, if you take the square root of the variance, you get the standard deviation!\n",
    "\n",
    "- Or the other way around, if you multiply the standard deviation by itself, you get the variance!\n",
    "\n",
    "To calculate the variance you have to do as follows:\n",
    "\n",
    "- 1. Find the mean:\n",
    "\n",
    "(32+111+138+28+59+77+97) / 7 = 77.4\n",
    "\n",
    "- 2. For each value: find the difference from the mean:\n",
    "\n",
    "\n",
    "- 3. For each difference: find the square value:\n",
    "\n",
    "- 4. The variance is the average number of these squared differences:\n",
    "\n",
    "(2061.16+1128.96+3672.36+2440.36+338.56+0.16+384.16) / 7 = 1432.2\n",
    "Luckily, NumPy has a method to calculate the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39b168a-3888-4b78-a598-875ecb285290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1432.2448979591834\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [32,111,138,28,59,77,97]\n",
    "\n",
    "x = numpy.var(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7323bed2-b284-4843-b6fb-e769b257928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([2, 4, 4, 4, 5, 5, 7, 9])\n",
    "\n",
    "variance = np.var(data)\n",
    "print(\"Variance:\", variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3475ea-0aa4-4923-a5b0-957b61f5282f",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da86113c-723e-4604-8ba9-23df23ccd23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.84501153334721\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "speed = [32,111,138,28,59,77,97]\n",
    "\n",
    "x = numpy.std(speed)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ae72e-1254-4ad7-af2f-95faf6430d1c",
   "metadata": {},
   "source": [
    "### Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0d709-a173-45db-908d-b4aef0bc914d",
   "metadata": {},
   "source": [
    "- Standard Deviation is often represented by the symbol Sigma: σ\n",
    "\n",
    "- Variance is often represented by the symbol Sigma Squared: σ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26fdb0-167e-4d4c-915b-c3f74b481319",
   "metadata": {},
   "source": [
    "## Machine Learning - Percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5c201-9d87-4a51-8a70-86386b862b0c",
   "metadata": {},
   "source": [
    "In machine learning, percentiles are statistical measures used to describe the distribution of a dataset by dividing it into hundred equal parts. Percentiles are particularly useful for understanding how individual data points rank relative to the entire dataset. They are commonly used in exploratory data analysis, data preprocessing, and model evaluation.\n",
    "\n",
    "### Calculating Percentiles\n",
    "The \\(p\\)-th percentile of a dataset is the value below which a certain percentage of observations fall. For example, the 50th percentile (also known as the median) represents the value below which 50% of the observations fall.\n",
    "\n",
    "The formula to calculate the \\(p\\)-th percentile is as follows:\n",
    "\n",
    "\\[\n",
    "\\text{{Percentile}}_p = \\text{{K-th value in the sorted dataset}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\(p\\) is the desired percentile (e.g., 50 for the median, 25 for the first quartile, 75 for the third quartile, etc.).\n",
    "- \\(K\\) is calculated as \\(\\frac{{p \\times (n + 1)}}{{100}}\\), where \\(n\\) is the number of observations in the dataset. Note that if \\(K\\) is not an integer, it is common to interpolate between the two closest values.\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Consider the dataset: [2, 4, 4, 4, 5, 5, 7, 9].\n",
    "\n",
    "1. **Sort the Dataset**: [2, 4, 4, 4, 5, 5, 7, 9]\n",
    "2. **Calculate the Index**: For the 50th percentile (median), \\(K = \\frac{{50 \\times (8 + 1)}}{{100}} = 4.5\\).\n",
    "3. **Interpolate**: Since \\(K\\) is not an integer, we interpolate between the 4th and 5th values in the sorted dataset.\n",
    "4. **Calculate the Percentile**: The 50th percentile is the average of the 4th and 5th values, which is \\((4 + 5) / 2 = 4.5\\).\n",
    "\n",
    "So, the 50th percentile (median) of the dataset is 4.5.\n",
    "\n",
    "### Applications in Machine Learning\n",
    "\n",
    "- **Data Understanding**: Percentiles provide insights into the distribution and spread of data points in a dataset.\n",
    "- **Outlier Detection**: Percentiles are used to identify outliers by comparing individual data points to specific percentiles.\n",
    "- **Feature Engineering**: Percentiles can be used to create new features or transform existing features, particularly in skewed distributions.\n",
    "- **Model Evaluation**: Percentiles-based metrics are used to evaluate model performance and assess predictions across different percentiles of the dataset.\n",
    "\n",
    "### Example in Python\n",
    "\n",
    "Here's how you can calculate percentiles using Python with a dataset stored in a list:\n",
    "\n",
    "```python\n",
    "data = [2, 4, 4, 4, 5, 5, 7, 9]\n",
    "\n",
    "# Calculate the 50th percentile (median)\n",
    "median = np.percentile(data, 50)\n",
    "print(\"Median:\", median)\n",
    "\n",
    "# Calculate the 25th and 75th percentiles (first and third quartiles)\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "print(\"First Quartile (Q1):\", q1)\n",
    "print(\"Third Quartile (Q3):\", q3)\n",
    "```\n",
    "\n",
    "### Importance in Machine Learning\n",
    "\n",
    "- **Data Understanding**: Percentiles provide insights into the distribution of data points and help in identifying skewness and outliers.\n",
    "- **Preprocessing**: Percentiles-based transformations can be applied to features to make them more suitable for certain algorithms or to handle skewed distributions.\n",
    "- **Model Training**: Percentiles are used in various techniques and algorithms to handle data variability and make models more robust.\n",
    "- **Model Evaluation**: Percentiles-based metrics provide a comprehensive evaluation of model performance across different segments of the dataset.\n",
    "\n",
    "By effectively understanding and utilizing percentiles, machine learning practitioners can gain valuable insights into their data, improve model performance, and make informed decisions throughout the machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd22d4f4-5975-45bf-9254-3383ebfc9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median: 4.5\n",
      "First Quartile (Q1): 4.0\n",
      "Third Quartile (Q3): 5.5\n"
     ]
    }
   ],
   "source": [
    "data = [2, 4, 4, 4, 5, 5, 7, 9]\n",
    "\n",
    "# Calculate the 50th percentile (median)\n",
    "median = np.percentile(data, 50)\n",
    "print(\"Median:\", median)\n",
    "\n",
    "# Calculate the 25th and 75th percentiles (first and third quartiles)\n",
    "q1 = np.percentile(data, 25)\n",
    "q3 = np.percentile(data, 75)\n",
    "print(\"First Quartile (Q1):\", q1)\n",
    "print(\"Third Quartile (Q3):\", q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b90597b6-5399-476f-aeda-e65159c6634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
    "\n",
    "x = numpy.percentile(ages, 75)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4a19e03-10e2-4c9e-b35e-b4635969fa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
    "\n",
    "x = numpy.percentile(ages, 25)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac5f8354-3aa4-4a79-bae0-107c6bdcbced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
    "\n",
    "x = numpy.percentile(ages, 50)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7e76204-6d30-4e1c-94b4-563cf98588ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "ages = [5,31,43,48,50,41,7,11,15,39,80,82,32,2,8,6,25,36,27,61,31]\n",
    "\n",
    "x = numpy.percentile(ages, 90)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b299d-64cc-4031-b52d-44d62630cce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
